{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text similarity probings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy, pandas\n",
    "\n",
    "import pathlib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "WD = str(pathlib.Path().absolute()) + '/'\n",
    "PROJECT_FOLDER = WD + '../'\n",
    "PROBINGS_FOLDER = PROJECT_FOLDER + 'probings/'\n",
    "DATA_FOLDER = PROJECT_FOLDER + 'data/'\n",
    "\n",
    "sys.path.append(PROBINGS_FOLDER)\n",
    "\n",
    "from similarity import dataset_similarity\n",
    "\n",
    "\n",
    "# utilities\n",
    "def similarity_dataframe(inputs, similarity):\n",
    "    idx = numpy.dstack(numpy.unravel_index(numpy.argsort(similarity.ravel()), similarity.shape)).squeeze()\n",
    "    pairs = [(inputs[i], inputs[j], similarity[i, j]) for i, j in idx if not numpy.isnan(similarity[i, j])]\n",
    "    df = pandas.DataFrame(pairs, columns=['premise_1', 'premise_2', 'similarity_score'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = WD + '../data/'\n",
    "\n",
    "input_texts = list([\n",
    "    DATA_FOLDER + 'rte/val.jsonl',\n",
    "    DATA_FOLDER + 'axb/val.jsonl',\n",
    "    DATA_FOLDER + 'axg/val.jsonl',\n",
    "    DATA_FOLDER + 'mnli/val.jsonl',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity according to different metrics\n",
    "\n",
    "By default, we use `cosine` similarity. `dot` and `euclidean` distances are also available.\n",
    "We also provide two similarity modules, [SBERT](https://arxiv.org/pdf/1908.10084.pdf) and [Infersent](https://arxiv.org/pdf/1705.02364.pdf), which you can choose through the `model` parameter of the `dataset_similarity` function.\n",
    "To use SBERT, set `similarity_model` to any of the pretrained models you can find in [here](https://www.sbert.net/docs/pretrained_models.html), while to use `Infersent` set it to `infersent`.\n",
    "It defaults to `'stsb-distilbert-base'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/mattiasetzu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████| 1/1 [00:43<00:00, 43.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "similarity_model = 'infersent'\n",
    "inputs, inputs_similarities = dict(), dict()\n",
    "for dataset in tqdm(input_texts[-1:]):\n",
    "    # load data\n",
    "    data = pandas.read_json(dataset, lines=True)\n",
    "    data = data.drop('idx', axis='columns')\n",
    "    data = data['premise'].values.tolist()\n",
    "    \n",
    "    dataset_name = dataset.split('/data/')[1].split('/')[0]\n",
    "    inputs[dataset_name] = data\n",
    "    inputs_similarities[dataset_name] = dict()\n",
    "    \n",
    "    for distance in ['euclidean', 'dot', 'cosine'][2:]:\n",
    "        similarities_file = DATA_FOLDER + 'probings/' + similarity_model + '_' + dataset_name + '_pairwise_similarities_by_' + distance + '.dat'\n",
    "\n",
    "        if os.path.isfile(similarities_file):\n",
    "            inputs_similarities[dataset_name][distance] = numpy.load(similarities_file, allow_pickle=True)\n",
    "        else:\n",
    "            _, similarity_matrix = dataset_similarity(dataset, model=similarity_model, metric=distance)\n",
    "            numpy.matrix.dump(similarity_matrix, similarities_file)\n",
    "            inputs_similarities[dataset_name][distance] = similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "from bokeh.io import output_file, output_notebook, show, export_png\n",
    "from bokeh.models import BasicTicker, ColorBar, ColumnDataSource, LinearColorMapper, PrintfTickFormatter\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.sampledata.unemployment1948 import data\n",
    "from bokeh.transform import transform\n",
    "\n",
    "# palettes\n",
    "from bokeh.palettes import RdBu7\n",
    "\n",
    "\n",
    "def similarity_heatmap(premises, data, dataset_name, colors=RdBu7, out_file=None):\n",
    "    mapper = LinearColorMapper(palette=colors, low=-1, high=+1)\n",
    "    \n",
    "    vals = list()\n",
    "    for i in range(len(inp)):\n",
    "        for j in range(i + 1, len(inp)):\n",
    "            vals.append((str(i), str(j), sim[i, j], i, j))\n",
    "    data = pandas.DataFrame(vals, columns=['x', 'y', 'val', 'x_int', 'y_int']).sort_values(by=['x_int', 'y_int'])\n",
    "    data = data.pivot(index='x', columns='y', values='val')\n",
    "    data.columns.name = 'y'\n",
    "    df = pandas.DataFrame(data.stack(), columns=['val']).reset_index()\n",
    "    source = ColumnDataSource(df)\n",
    "    \n",
    "    x_index = [str(el) for el in sorted([int(x) for x in list(data.index)])]\n",
    "    y_index = [str(el) for el in sorted([int(y) for y in list(reversed(data.columns))])]\n",
    "    \n",
    "    p = figure(plot_width=6000, plot_height=6000, title='Pairwise premise similarity on ' + dataset_name,\n",
    "               x_range=x_index, y_range=y_index)\n",
    "    p.rect('x', 'y', width=1, height=1, source=source, line_color=None, fill_color={'field': 'val', 'transform':mapper})\n",
    "    \n",
    "    color_bar = ColorBar(color_mapper=mapper, location=(0, 0))\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    p.axis.major_label_text_font_size = \"0px\"\n",
    "\n",
    "    export_png(p, filename=out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity matrices\n",
    "\n",
    "**Note: run the next cell only on a server with high RAM capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for inp, sim, dataset in zip(inputs, inputs_similarities, ['rte', 'axb', 'axg', 'mnli']):\n",
    "#    similarity_heatmap(inp, sim, dataset, out_file=dataset + '_pairwise_similarities.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "for dataset in ['rte', 'axb', 'axg', 'mnli']:\n",
    "    inp = inputs[dataset]\n",
    "    for distance in ['euclidean', 'dot', 'cosine']:\n",
    "        df = similarity_dataframe(inp, inputs_similarities[dataset][distance])\n",
    "        df['dataset'] = dataset\n",
    "        df['distance'] = distance\n",
    "        df = df[['dataset', 'premise_1', 'premise_2', 'similarity_score', 'distance']]\n",
    "        dfs.append(df)\n",
    "pairwise_similarities = pandas.concat(dfs, axis='rows')\n",
    "pairwise_similarities['model'] = similarity_model\n",
    "pairwise_similarities = pairwise_similarities[['dataset', 'model', 'premise_1', 'premise_2', 'similarity_score', 'distance']]\n",
    "pairwise_similarities.to_csv(DATA_FOLDER + '/probings/infersent_pairwise_similarities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles by dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_similarities.groupby(['dataset', 'distance'], sort=False).describe(percentiles=[0.9, 0.95, 0.9975, 0.999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise similarities percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all rows\n",
    "pandas.set_option('display.max_rows', None, 'display.max_columns', None)\n",
    "# show full columns\n",
    "pandas.set_option('display.max_colwidth', None)\n",
    "\n",
    "by_premise_groups = pairwise_similarities.groupby(['premise_1', 'distance'], sort=False)\n",
    "by_premise_groups_percentiles = by_premise_groups.describe(percentiles=[.5, .75, .995, .9975, .999])['similarity_score'][['mean', 'std', 'min', '99.5%', '99.75%', '99.9%']]\n",
    "by_premise_groups_percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top k most similar instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "sorted_groups = by_premise_groups.apply(lambda x: x.sort_values('similarity_score', ascending=False))\\\n",
    "                                        .drop(['premise_1', 'distance'], axis='columns')\\\n",
    "                                        .groupby(['premise_1', 'distance'])\\\n",
    "                                        .head(K)[['premise_2', 'similarity_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_groups.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top k least similar instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "sorted_groups = by_premise_groups.apply(lambda x: x.sort_values('similarity_score', ascending=True))\\\n",
    "                                        .drop(['premise_1', 'distance'], axis='columns')\\\n",
    "                                        .groupby(['premise_1', 'distance'], sort=False)\\\n",
    "                                        .head(K)[['premise_2', 'similarity_score']]\n",
    "sorted_groups.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
